[
["index.html", "My Final College Paper Introduction", " My Final College Paper Nathaniel Brown May 20xx Introduction Welcome to the R Markdown thesis template. This template is based on (and in many places copied directly from) the Reed College LaTeX template, but hopefully it will provide a nicer interface for those that have never used TeX or LaTeX before. Using R Markdown will also allow you to easily keep track of your analyses in R chunks of code, with the resulting plots and output included as well. The hope is this R Markdown template gets you in the habit of doing reproducible research, which benefits you long-term as a researcher, but also will greatly help anyone that is trying to reproduce or build onto your results down the road. Hopefully, you won’t have much of a learning period to go through and you will reap the benefits of a nicely formatted thesis. The use of LaTeX in combination with Markdown is more consistent than the output of a word processor, much less prone to corruption or crashing, and the resulting file is smaller than a Word file. While you may have never had problems using Word in the past, your thesis is likely going to be about twice as large and complex as anything you’ve written before, taxing Word’s capabilities. After working with Markdown and R together for a few weeks, we are confident this will be your reporting style of choice going forward. Why use it? R Markdown creates a simple and straightforward way to interface with the beauty of LaTeX. Packages have been written in R to work directly with LaTeX to produce nicely formatting tables and paragraphs. In addition to creating a user friendly interface to LaTeX, R Markdown also allows you to read in your data, to analyze it and to visualize it using R functions, and also to provide the documentation and commentary on the results of your project. Further, it allows for R results to be passed inline to the commentary of your results. You’ll see more on this later. Having your code and commentary all together in one place has a plethora of benefits! Who should use it? Anyone who needs to use data analysis, math, tables, a lot of figures, complex cross-references, or who just cares about the final appearance of their document should use R Markdown. Of particular use should be anyone in the sciences, but the user-friendly nature of Markdown and its ability to keep track of and easily include figures, automatically generate a table of contents, index, references, table of figures, etc. should make it of great benefit to nearly anyone writing a thesis project. "],
["1-abstract.html", "Chapter 1 Abstract", " Chapter 1 Abstract The proposed study is an investigation of Bayesian statistical models and analyses for problems arising in shooting a basketball. The data comes from the Duke Men’s Basketball team’s player-tracking data from the SportVU cameras of STATS, LLC. Goals will be to explore, develop and apply Bayesian models to existing and new data on shooting outcomes, to understand and evaluate questions of inherent random variation, changes over time in shooting performance, and issues related to the “Hot Hand” concept in sports. (talk about models you fit) (talk about results) "],
["2-litreview.html", "Chapter 2 Literature Review", " Chapter 2 Literature Review 2.0.1 how do I get the full citations to show up and not just last name and year? Gilovich, Vallone, &amp; Tversky (1985) In this seminal research paper from Cognitive Psychology, Thomas Gilovich, Robert Vallone, and Amos Tversky investigate peoples’ belief in the Hot Hand in Basketball. The Hot Hand is the concept that the probability of a success increases for trials that follow a success in a binary sequence; in basketball, these binary events are shot attempts. The methods in this paper include an analysis of shot attempts from the Philadelphia 76ers of the National Basketball Association (NBA) in the 1981 season, analysis of free-throw attempts from the Boston Celtics in the 1981 and 1982 seasons, and a controlled shooting drill using male and female varsity basketball players at Cornell University. Statistical techniques they used to attempt to detect streakiness in the data included Walf-Wolfowitz run tests, autocorrelation tests on consecutive shot attempts, goodness-of-fit tests for the distribution of succesess, and paired t-tests comparing the mean of makes following a make to that of makes following a miss. In addition to this analysis of shooting, this research also contained a survey of basketball fans, that gauged how much people believed success probabilities changed given a success or a failure. The statistical tests did not detect significant evidence supporting the Hot Hand in basketball. Albert &amp; Williamson (1999) In this paper, Jim Albert attempts to improve upon the low-powered tests of Gilovich, Vallone, and Tverky’s 1985 paper on the Hot Hand. Albert formally defines “streakiness” as the presence of nonstationarity (nonconstant probability between trials) or autocorrelation (sequential dependency). Albert uses Gibbs sampling to approximate posterior densities and simulate data, then fits two types of models on binary data from baseball and basketball to try to characterize streakiness. He fits an overdispersion model to detect nonstationarity, and a markov switching model to detect sequential dependencies. While he did not uncover strong evidence for the hot hand, one of his takeaways was that overdispersion decreases as time goes on in basketball free throw shooting data. Koehler &amp; Conley (2003) Koehler and Conley analyze shooting streaks in basketball using four years of data from the National Basketball Association’s Three-Point Contest. They test for sequential dependency using conditional probabilities of shot success (e.g. P(Hit | 3 Hits) compared to P(Hit | 3 Misses)), and they test runs analysis. One unique perspective they took in assessing streakiness in basketball is the comments of the commentators during the broadcast of the contest. They found that when a commentator described a player as “On Fire” or “On a Roll”, etc., as a reaction to a shooter going on a streak, it was not predictive of future shooting outcomes. Bar-Eli, Avugos, &amp; Raab (2006) This paper is a review of previous hot hand research. It reviews several papers investigating the concept of the “hot hand” in several sports such as basketball, baseball, volleyball, and horeshoe, and other fields such as cognitive science and economics. Bar-Eli, Avugos, and Raab evaluate the datasets, the tests and statistics used, and the conclusions of each study. Overall, the authors summarize 13 papers that oppose the hot hand phenomenon, and 11 that support it; they also acknowledge that the scientific evidence for the hot hand is weaker than the evidence against it, and it is typically more controversial. Instead of just looking to answer whether the hot hand exists, Bar-Eli, Avugos, and Raab also examine how people define a “hot hand”, and the psychological factors behind the belief in it, such as the gambling and game strategy. Ryan Wetzels (2016) In this research paper, Wetzels uses Bayesian analysis with a Hidden Markov Model to investigate the Hot Hand Phenomenon. Miller &amp; Sanjurjo (2016) Intro Inherent subtle but substantial selection bias when measuring conditional dependence of current outcomes on past outcomes in sequential data. We prove that for any finite sequence of binary data, in which each outcome of &quot;success&quot; or &quot;failure&quot; is determined by an i.i.d. random variable, the proportion of 1s among the outcomes that immediately follow a streak of consecutive 1s is expected to be strictly less than the underlying (conditional) probability of success. P(H) &gt; P(H | H) &gt; P(H | H, H) &gt; P(H | H, H, ... Hk) &gt; ... bias decreases as sequence (experimental trials, num coinflips) gets longer; bias increases as streak (condition, num heads) size increased example table with n=3, k=1 for HHH and HHT, there are two flips after the streak prereq for THT, HTT, HTH, THH, there is one flip after the streak for TTH, TTT, there are zero each seq has an equal prob of happening, but in group a. you record 2 events, b. is 1, and c. is 0. Therefore, the group a. flips are individually weighted the least. This means that individual flips among a small group of heads inherently get a lower weight. -&gt; heads get a lower prob. how to unbias flip indefinitely until you get m trials that follow a streak, instead of flipping exactly n times (negbinom sampling) eliminate overlap by dividing your n trials into bins (that may or may not break up some streaks) (explanation was confusing) the bias implies that streaks within finite sequences are expected to end more often than continue (relative to the underlying probability) which can lead both the gambler to think that an i.i.d process has a tendency towards reversal, and the hot hand researcher to think that a process is i.i.d. when it actually has a tendency towards momentum. you should write a function to simulate this using binomial trials! Bias (theoretical results) proof show that: if X is binary seq of iid randvars s/t p = p(x_i = 1) = p(x_i = 1| k-length streak), then this procedure yields a biased estimate of the conditional probability the probability of seeing a streak is &lt; p, ==&gt; E[p(x=1|streak)] &lt; p relationship to know results (like SWOR) any binary seq of n trials will have n1 successes and n0 := n-n1 failures prior odds of success = n1/n0 for trials following streak of k 1s ( denoted in paper as I_1k(x) ), odds dec. prior odds have 2 updating factors &amp; they both cause drop in odds when t &lt; n first factor: (n1-k)/n1 &lt; 1 reflects constraint of the finite number of available trials to select from info gained upon learning k of the n1 successes are no longer available, which leads to a SWOR effect on the prior odds bias increases as k (streak length) increases second factor: too complicated to type out. some ratio of expectations. reflects constraint of arrangement of successes in the seq info gained upon learning that k 1s are consec. and precede t. if k-streak occurs, x(t+1) WILL be in I_1k, and x(t+2),…,x(t+k) MIGHT be. else, x(t+1), …, x(t+k) CANNNOT be in I_1k. SWOR formula bias is determined not by size of n1, but by number of (overlapping) instances of k consecutive 1s in the first n???1 trials, which depends on both n1 and their arr. overlapping words paradox? Quantifying the Bias enumerating all possible seqs for given n and n1 is computationally expensive cool magnitude of bias plots visualizing P1k - P0k Hot Hand Application debiasing GVT data/tests t-test shift the estimated difference Dk := p1k - p0k “the bias adjustment is made by subtracting the expected difference (a player’s overall percentage) from each player’s observed difference. “results in 19 of the 25 players exhibiting hot hand shooting” p&lt;0.01 permutations test permutation test is invulnerable to the bias under the null of constant prob, each perm. of 1s and 0s is eq. likely process: . record n1 hits and n0 misses . calculate Dk for each possible arrangement of the sequence . the distribution of Dks should be left skewed . use dist to find how “significant”ly off obs Dk is. . agreeable with t-test thing debiasing other studies these studies are: Jagacinski et al. (1979) (read this!!!) Koehler and Conley (2003), (the three-point shootout one) Avugos et al. (2013a) (no raw data provided ???) and Miller and Sanjurjo (2014). (read this too) 2003: only median 49 shots per player. severly underpowered. when debiasing, there is a significant improvement. 1979 &amp; 2014: few players, but many shots per players debiasing agrees and players exhibit streakiness belief in the hot hand GVT: players believe in hot hand, hot hand does not exist this: of course people can still overreact to a few consecutive makes, but it is not completely a fallacy &quot;an understanding of the extent to which decision makers&#39; beliefs and behavior do not corecposnd to the actual degree of hot hand shooting may have important implications for decision making more generally. hot hand is not a binary issue. it can exist, and belief can be too strong. ask fans, players, and decision makers. ironically, after one make, ppl tend 2 predict miss more, cause theyre biased towards alternating seqs. prediction questions are more informative of HH belief than qualitative ones GVT calculated avg correlation of .04 from prediction/betting game. However, even with an assumed knowledge of the change in shooting states, the expected correlation would be .07, assuming pc = 0.45 and ph = 0.55. reanalysis of betting data, using pooled data instead of indiv. avg correlation bumps up to 0.07, and p&lt;0.001 weakness in GVT prediction exercise: under the null, the predictions should be more accurate than chance following streaks, but under the alt, if the players are correctly perceiving when hot state activates, then there won’t be much of a difference in their accuracy between hot and cold states. hmmmm interesting logic. 2014 paper found that semi-pro players&#39; rankings of teammates respective increases in FG% following 3-streaks are highly correlated with actual increase in performance (-0.60) players may be able to perceive hot hand in real time, which would require seeing more factors than binary streaks. (technique, body lang, etc.) &quot;this suggest the possibility of conducting experiements in which experienced players (or coaches) are incenivixed to predict the shot outcomes of players that they are familiar with, but only predict when they feel sufficiently confident about their ability to do so accurately&quot; Gambler Application gamblers mistakenly apply large sample properties to small samples (they expect things to even out) humans typically remember things in (relatively) small sample sizes, so sample size neglect occurs naturally (we overfit to what most recently happened) even for experienced decision makers. there is scientific reasoning to gamb fall bias tho: when n &gt; 4, 1110 is mathematically more likely to occur than 1111, which may explain why people believe that probability of 0 is greater than 0.5 after three 1s in a row. Conclusion gambler sees reversal in an iid process, while researchers see iid in a momentous process –&gt; Jagacinski, Newell, &amp; Isaac (1979) Abstract college ballers predicting their own shots outcome either before release, right after release, or halfway to the basket, were no better at predicting than passive observers. some evidence found for seq. dep., but not to the degree one found in bball lore Intro 1977 paper found bball players cannot predict immediate performance outcomes better than an observer. but they can better predict their own outcomes during the execution of their action. internal, non-visual cues from their own receptive feedback signal detection analysis (sensitivity = true positive rate) two motivations: player sensitivity and existence of seq. dep. the experiment: subjects: 3 pairs of U of Ill. grad students who played mens college ball as undergrads apparatus: portable wooden panel with sensors that shut off lights when a basketball passed thru. placed at midpoint of shot location, in a regular bball gym procedure: 10 sessions, approx 1.5 hr each, one pair per session. subjects alternate roles of shooter and observer for 6 blocks of 60 trials. session 1 is for practice, while 2-10 were experimental in prax, there was lights on, lights off on midpt, and lights off on release. to familiarize subjects with conditions, and find distance with 55% success rate both subjects would predict outcome on 6-point scale. both subjects had headphones with white noise playing shots were taken every 10ish seconds. incentive of 5 cents per successful shot, and -10 for each late prediction 540*3 = 1620 shots per person? results signal detection analysis the measure of sensitivity (A_g) was area under ROC curve average sensitivities were 0.5ish (approx chance) for pre-release pred. but good for at release or post release shooters were not more sensitive than observers seq dep analysis 4 subjects had a significant p-value for alt hyp: p(H|H) &gt; p(H|M) in general, subjects as shoots &amp; obs were optimistic in that p(Hpred|H) &gt; p(Hpred|M) discussion equivalent sensitivity in shot prediction from shooters and observers suggests that shooters can’t use internal cues to predict shot EVEN WHEN THE LIGHTS WERE OFF AFTER RELEASE!!! only subjects 5 &amp; 6 were slightly above chance in predictions as shooters when lights stayed on OFF 1st &lt; OFF 2nd &lt; OFF 3rd weak positive recency (streakiness, for makes or misses) WAS FOUND!!!! occurred mostly in OFF trial. optimism thing occurred mostly in the ON trial, even though it would have been more justified in the OFF trial. suggests that shooters’ beliefs in hotness may depend on other factors such as bball lore rather than visual feedback. possible that the lore is a result of lack of awareness of statistical fluctuations within a game, players usually take a small number of shots, so it would take very large changes in hot hit prob to be measurable in-game. this controlled data does not suggest these large changes exist. Albert (1993) intro Albright used 2 models on 501 players: “null” binom model with test stats related to streaks logis regress using predictors abt “recent success” aka history, &amp; situation concluded that few players were signif streaky; not enough to reject null tho streakiness effects are small in magnitude if they exist (overstated by media) concerns about power (signal detection) simple technique: look for peaks and valleys in moving avg plot Situational Variables control for factors such as Home/Away, pitcher handedness, runners on bases, etc. forward selection to determine significant ones for each player! predictor measuring recent success (hits in last 20 AB) the effect was negative! :O does hit prob change across season? pitcher ERA seemed to be the only generally signif predictor. try diff approach. if we ignore all situational &amp; historical vars, then we get binom trial moving average using d-length bins, also lag-d autocorr of moving avgs (d=4) one model for streakiness Markov sqitching again! latent variables Z1.ZT. Zi = 1(hot during game i) symmetric transition matrix with rows ((0.9, 0.1),(0.1,0.9)) (pswitch = 0.1) after they run on real data, they sim binom data to observe false negative possibility &quot;random data can display similar patterns&quot; conclusion difficult to distinguish batters from coin tosses ??? doesn&#39;t mean streakiness doesn&#39;t exist, just that it&#39;s subtle. model could improve by having more than two states Albert (2013) Intro sneaky patterns in baseball many ways of measuring success (hits, strikeouts, HR) many ways of measuring streakiness, (runs, variation of movavgs, BF) &amp; they all may vary in how well they can detect deviation from a binomial model under null mod, some players will appear streaky by chance (multiplicity). so look at streakiness dist. btwn all players to see if there is really streakiness overview of the paper (Albert, 2008) binary outcomes grouped into bins. and testing for diff in probs across bins. measure lack of randomness (clumpiness) by sum2 of spacings, then perm test natural model for spacings assumes iid geom dists with diff probs. streaky mod assumes probs are diff and dist according to beta dist. Binary seq and “spacings” intro consider binary data for a player. spacings {y}1n = num(0)s btwn conseq 1s 101000001100 ??? y={0,1,5,0,2} classical perm test to quantify the amount of non-random streakiness in data clump stats u can use: runs, bins, lag-1 autocorr, fxn of spacings f(y) like (SSq(y), Entropy(y), sum of 3 largest spacings, etc. here they use SSqs. S = SUM(yi2) given n1 successes, there are (n choose n1) arrangements for each combination simulated: randomly permute 0s and 1s and compute clumpiness stat S repeat m times (they used m=1000) to get approx null distribution of S then calculate p-value of Sobs Bayesian &quot;test&quot; (BF) BFstreak = p(y|Mstreak)/p(y|Mconst) = amount of support for Mstreak over Mconst Actually doing a Bayesian test Consistent and streaky models since yI represents discrete waiting time (in units of “outs”) we use geom f(y1|pi) = pi(1-pi)^(yi) where y is any natural number consistent model if not streaky then all pi are equal unknown constant hitting prob p has the prior g(p) = 1/(p(1-p)) streaky model pi vary pi ~ Beta(K, K(1-) for all i (K=precision, =mean) as K ??? , Mk ??? Mconst BF yeah just showing calculus methods and stuff Specifying K (difficult to assess) calculate BF’s for varying K’s K inc ??? BF inc you could also do a true subjective prior make guess at std dev of pi&#39;s, then calc K using empirical mean \\eta. n=100, = approx 0.3, prior sd = 0.1 ??? prior K = 3 Patterns of Streakiness in Hits streakiness in 2011 data more at-bats ??? lower BF ??? more evidence towards null p-vals and BF’s generally agree with each other. alternative BF method (by Albert (2008)) group data into bins (nb=10) and see if probs change much across bins used same beta dist for p of each bin. results were similar ???? comparing to chance calced BFs on 200 simulations of 2011 season with all batters using null model expect ??-error rate of 19ish% under null model.this is LARGER than theobserved proportion of streaky hitters (16%).??? “predictive p-value” = prob that simmed ??-errors exceed observed positives changing definition of success: strikeouts instead of hits patterns in 2011 season hitting is not indicative of skill, while striking out indicates a lack of skill expect ??-error rate of 17ish% under null model.this is SMALLER than the observed proportion of streaky hitters (19.5%).???? looking deeper into strikeout data observing indiv players. instead of just fraction of streaky players in a season. only two players were streaky for &gt; 2 seasons.only 12 for 2 consec seasons conclusion a new way of presenting streakiness.spacings looked at moving percentages, not correlations BF quantifies evidence for null or alt.freq test only quantifies evidence Mike West &amp; Harrison (1997) M. West, Harrison, &amp; Migon (1985) Prado &amp; West (2010) "],
["3-data.html", "Chapter 3 Data", " Chapter 3 Data The data for this analysis comes from SportVU, a player-tracking system from STATS, LLC. that provides precise coordinates for all ten players and the ball at a rate of 25 times per second. The Duke University Men’s Basketball team permitted the use of their SportVU data from the 2014 to 2017 basketball seasons for this project. However, since the ability to record this data depends on specialized tracking cameras, Duke does not have this data for every game they play—only home games, and a few road games in arenas that had the techology installed. Therefore, there is some missing data blank. For my analysis, I use the following associated files for each game: Final Sequence Play-by-Play Optical: This dataset comes in an a semi-structured Extensible Markup Language (XML) file, where there is a unique element for each “event” (an event is a basketball action such as a dribble, pass, shot, foul, etc.). Each event element has attributes of the type of event, the time of the event, and the player who completed the action. I use these files to uncover when a shot is attempted in a game, who attempted the shot, and the result of the shot attempt. Box Score Optical: I use this dataset to match the names and ids of players who were in the game. This is also an XML file, with elements corresponding to individual players. These elements contain attributes describing information about the player (e.g. team name, jersey number) and various statistics for the game (e.g. points, assists, distance run). Final Sequence Optical: This XML file contains the locations of all ten players and the ball during precise time intervals within the game. Each timeunit has a unique element, and these elements have attributes describing the locations. I merge this with the Play-by-Play on the time stamp to obtain the shooter’s location at the moment of a shot attempt. "],
["4-proc.html", "Chapter 4 Procedure", " Chapter 4 Procedure Using data that consists of a time-stamped sequence of shot locations and outcomes, we develop a novel analysis using dynamic generalized linear models, or DGLMs (West, Migon, and Harrison, 1985) (West and Harrison, 1997), for binary time series. These models allow for time-varying shot attempt and success parameters within a game and between games. The models provide flexibility in adapting to changes in the frequency of shot attempts, and to changes in scoring probabilities conditional on a shot attempt. The formal Bayesian analysis allowe us to produce full quantified inferences on such patterns over time, with probabilistic summaries of the within-game and between-game outcomes. For each game, this will be a full statistical characterization and quantification of the player shooting tendencies and outcomes, which provides understanding of inherent variability (or “randomness”) for the player, and formal assessments of differences in patterns game-to-game. I am also considering a two-state Hidden Markov Switching Model that parallels and extends these models; the two potential states for each shot attempt are a “high” probability or a “low” probability of making the next shot, given the features of the current and previous possessions. "],
["5-model.html", "Chapter 5 Models", " Chapter 5 Models library(mvtnorm); library(dplyr); library(ggplot2) #generating shot success probabilities #theta &lt;- matrix(c(-0.5, 1.5, -5.5)) #GLM parameters (intercept, angle, log distance) datafolder &lt;- &quot;C:/Users/Nathaniel Brown/Desktop/DMBBall Data&quot; source(&quot;C:/Users/Nathaniel Brown/Documents/GitHub/thesis-sp18-brown-hothand/sportvu_fxns.R&quot;) Warning: package &#39;xml2&#39; was built under R version 3.3.3 id1 &lt;- 887661 id2 &lt;- 842296 plot(x=allgameshots$x2[allgameshots$result == 1 &amp; allgameshots$globalplayerid==id2 &amp; allgameshots$season==2016], y=allgameshots$y2[allgameshots$result == 1 &amp; allgameshots$globalplayerid==id2 &amp; allgameshots$season==2016], col = &quot;red&quot;) points(x=allgameshots$x2[allgameshots$result == 0 &amp; allgameshots$globalplayerid==id2 &amp; allgameshots$season==2016], y=allgameshots$y2[allgameshots$result == 0 &amp; allgameshots$globalplayerid==id2 &amp; allgameshots$season==2016], col = &quot;blue&quot;) 5.0.0.1 GLM 5.0.0.2 Shot-by-Shot DGLM (only considering location, order, and result of each shot. not amount of time between shots). #TO DO: #send prof west the ft array (location and angle data, and intercept) and the binary y vector data. #make a mixed effects GLM with random player effect #use JAGS or rstan for logistic regression random effects MCMC playerid &lt;- id1 Z &lt;- allgameshots %&gt;% filter(globalplayerid == playerid) %&gt;% mutate(logr = log(r) - mean(log(r))) %&gt;% select(theta, logr) %&gt;% cbind(1,.) X &lt;- allgameshots %&gt;% filter(globalplayerid == playerid) %&gt;% select(x=x2, y=y2) y &lt;- allgameshots %&gt;% filter(globalplayerid == playerid) %&gt;% mutate(logr = log(r) - mean(log(r))) %&gt;% select(result) %&gt;% &#39;[[&#39;(1) ym &lt;- 94; xm &lt;- 50 shots &lt;- rep(TRUE,nrow(Z)) #no missing shots in this case tshot &lt;- which(shots) nshots &lt;- length(tshot) T &lt;- length(shots) #generating shot outcomes iy &lt;- which(y[!is.nan(y)] == 1) #initial parameters mod &lt;- (glm(y ~ theta + logr, data=Z, family=&quot;binomial&quot;)) #high p-values everywhere theta &lt;- coef(mod) p &lt;- length(theta) pscore &lt;- fitted(mod, type=&quot;response&quot;) q &lt;- rep(NaN, T) q[shots] &lt;- pscore par(xpd=TRUE) plot(0,0,type=&quot;n&quot;,xlim = c(0,T),ylim=c(0,1), ylab = &quot;probability&quot;, xlab = &quot;time index&quot;, main = &quot;GLM&quot;) points(tshot, q[tshot], pch=4, col = &quot;blue&quot;) points(tshot, y[tshot], pch=1, col = &quot;red&quot;) legend(x=T*.8, y=1.21, legend=c(&quot;probability&quot;, &quot;outcome&quot;), pch = c(4,1), col=c(&quot;blue&quot;, &quot;red&quot;)) par(xpd=FALSE) plot(X[iy,c(&quot;x&quot;,&quot;y&quot;)], ylim=c(0,ym), xlim=c(-xm,xm), col = &quot;red&quot;, pch = 3, xlab=&quot;x&quot;, ylab=&quot;y&quot;, main = &quot;Makes and Misses&quot;) points(X[-iy,c(&quot;x&quot;,&quot;y&quot;)], col =&quot;blue&quot;, pch = 1) abline(h=ym/2) points(0,0,col=&quot;red&quot;, cex=2) #Forward Filtering #set up DGLM and initial prior #first, set up covariates per time interval F &lt;- t(Z) p &lt;- dim(F)[1] #theta = state vector (GLM parameters) (px1) #F = the data...regression vectors for all t...aka the design matrix (pxT) #G = known evolution matrix ??????? #omega = evolution errors with 0 mean and known variance matrix W #g(.) = function to map eta to real line (logit) mt &lt;- theta Ct &lt;- diag(p) #mt = prior mean vector #Ct = prior covariance matrix #(theta[t-1]|D[t-1]) ~ N(mt[t-1], Ct[t-1]) delta &lt;- 1 #0.99 #discount factor; &quot;streaky parameter&quot; #forward filtering (FF) smt &lt;- matrix(rep(0,p*T), nrow=p) #save post means sCt &lt;- array(rep(0,p*p*T), dim = c(p,p,T)) #save post covars spt &lt;- rep(NaN, T) #save post prob success lmlik &lt;- rep(0,T) #marg lik per time int ishot &lt;- 0 rtst &lt;- array(NA, c(T,2)) for(t in 1:T){ if(t %in% tshot){ #current shot attempt index, and time ishot &lt;- ishot + 1 ti &lt;- tshot[ishot] ft &lt;- (F[,ishot]) %*% mt At &lt;- Ct %*% F[,ishot]/delta qt &lt;- (F[,ishot]) %*% At At &lt;- At/as.numeric(qt) #at = Gt*mt in txtbk, but = mt here. #Rt = Gt*Ct[t-1]*Gt&#39; + Wt in txtbk, but = Ct/delta here #f = F&#39;at = F&#39;mt #q = F&#39;RF = F&#39;Ct F (1/delta) #((lambda,theta)&#39; | Dt-1) ~ N( (f, a), ((q, F&#39;C/delta),(CF/delta, C)) ) #what is mu tho? #??????????????????????? #&quot;the samp dist of Yt depends on thetat only via the single quantity mut #prior: (mu|Dt) ~ N(f, q) #Vt &gt; 0 is scale parameter aka precision of distribution... #but precision of what??? what is b(Yt, Vt?) #Q = q + Vt #post: (mu|Dt) ~ N(f*, q*) #f* = #what is mu??? #f = F&#39;a which is #prior mean and var of linear predictor, and adaptive vector #compute approx prior Beta(r,s) params; update w/ numerical iterations for exact values eft &lt;- exp(ft) #crude initial values rt &lt;- (1+eft)/qt st &lt;- rt/eft rt &lt;- max(0.5, rt) st &lt;- max(0.5, st) #fts = ft* = posterior mean of ???? #qts = qt* = posterior variance of something ??? #iterative numerical solution # ep &lt;- 0.5; drt &lt;- 1; dst &lt;- 1; xt &lt;- matrix(c(rt, st)) # while(max(drt, dst) &lt; ep){ # r0t &lt;- psigamma(rt,0); s0t &lt;- psigamma(st,0) # r1t &lt;- psigamma(rt,1); s1t &lt;- psigamma(st,1) # fxt &lt;- c(r0t-s0t-ft, r1t+s1t-qt) # Axt &lt;- matrix(c(r1t, -s1t, psigamma(rt, 2), psigamma(st, 2)), ncol=2, byrow = TRUE) # xt &lt;- xt - solve(Axt, fxt) # drt &lt;- xt[1] - rt; dst &lt;- xt[2] - st # rt &lt;- xt[1]; st &lt;- xt[2] # } rtst[t,] &lt;- c(rt, st) if(rt &gt; 1000){ break } lmlik[t] &lt;- lgamma(rt+st) - lgamma(rt) - lgamma(st) + lgamma(rt+y[t]) + lgamma(st+1-y[t]) - lgamma(rt+st+1) + lgamma(2) - lgamma(1+y[t]) - lgamma(2-y[t]) rts &lt;- rt + y[t]; sts &lt;- st + 1-y[t] #posterior beta params #convert to mean and variance for linear predictor fts &lt;- psigamma(rts,0)-psigamma(sts,0); qts &lt;- psigamma(rts,1)+psigamma(sts,1) spt[t] &lt;- rts/(sts+rts) #update state parameters mt &lt;- mt+At%*%(fts-ft) Ct &lt;- Ct/delta - (At%*%t(At))*as.numeric(qt-qts) Ct &lt;- (Ct + t(Ct))/2 c(t, rt, st, mt) if(any(is.nan(mt))){ print(&quot;stop&quot;) break } } smt[,t] &lt;- mt; sCt[,,t] &lt;- Ct #saving } par(xpd=TRUE) plot(smt[1,],type=&quot;l&quot;, col = &quot;blue&quot;, xlab = &quot;shot index&quot;, ylab = &quot;online state mean&quot;, main = &quot;Dynamic Parameters&quot;) lines(smt[2,],type=&quot;l&quot;, col = &quot;orange&quot;) lines(smt[3,],type=&quot;l&quot;, col = &quot;yellow&quot;) legend(x=T*.75, y=4, legend = c(&quot;intercept&quot;, &quot;angle&quot;, &quot;log(distance)&quot;), pch = c(16), col = c(&quot;blue&quot;, &quot;orange&quot;, &quot;yellow&quot;)) plot(0,0,type=&quot;n&quot;,xlim = c(0,T),ylim=c(0,1), ylab = &quot;probability&quot;, xlab = &quot;time index&quot;, main = &quot;DGLM&quot;) points(tshot, spt[tshot], pch=4, col = &quot;blue&quot;) points(tshot, y[tshot], pch=1, col = &quot;red&quot;) legend(x=T*.8, y=1.21, legend=c(&quot;probability&quot;, &quot;outcome&quot;), pch = c(4,1), col=c(&quot;blue&quot;, &quot;red&quot;)) #arm::binnedplot(x=spt[tshot], y=y[tshot]-spt[tshot]) #Backward sampling nmc &lt;- 1000 #save posterior means and posterior success probs MCtheta &lt;- array(0, c(p, T, nmc)) MCq &lt;- array(0, c(T, nmc)) #begin BS at timeunit T thetat &lt;- rmvnorm(n=nmc, smt[,T], sCt[,,T]) #SOMETIMES sCT[,,T] IS NOT POSITIVE DEFINITE. DEPENDS ON RANDOM SEED. MCtheta[,T,] &lt;- t(thetat) MCq[T,] &lt;- 1/(1+exp(-thetat %*% F[,nshots])) #then recurse backwards ishot &lt;- nshots + 1 for(t in (T-1):1){ if(t %in% tshot){ ht = (1-delta)*t(array(smt[,t], c(dim(smt)[1], nmc))) + delta*thetat #run a simulation for each row of ht and each 3rd dim of sCt thetat &lt;- t(apply(ht, 1, rmvnorm, n=1, sigma = sCt[,,t]*(1-delta))) MCtheta[,t,] &lt;- t(thetat) ishot &lt;- ishot - 1; ti &lt;- tshot[ishot] MCq[t,] &lt;- 1/(1+exp(-thetat %*% F[,ishot])) } } #retrospective posterior summaries #posterior of shot probabilities? pr &lt;- t(apply(MCq[tshot,], 1, quantile, c(.025, .25, .5, .75, .975))) #get quantiles of each row plot(0,0, type=&quot;n&quot;, xlim = c(0,T), ylim=c(0,1), main = &quot;Posterior Probability&quot;, ylab=&quot;hit rate&quot;, xlab=&quot;time interval&quot;) lines(x=tshot, y=pr[,1], col = &quot;gray&quot;) lines(x=tshot, y=pr[,5], col = &quot;gray&quot;) polygon(c(tshot, rev(tshot)), c(pr[,1], rev(pr[,5])), col = &quot;gray&quot;, border = NA) lines(x=tshot, y=pr[,2], col = &quot;black&quot;) lines(x=tshot, y=pr[,4], col = &quot;black&quot;) polygon(c(tshot, rev(tshot)), c(pr[,2], rev(pr[,4])), col = &quot;black&quot;, border = NA) lines(x=tshot, y=pr[,3], col = &quot;red&quot;) points(x=1:T, y=y, pch=1) #posteriors of parameters from DGLM posterior_labels &lt;- c(&quot;Posterior Intercept&quot;, &quot;Posterior Angle&quot;, &quot;Posterior Log Distance&quot;) for(j in 1:p){ pr = t(apply(MCtheta[j,tshot,], 1, quantile, c(.025, .25, .5, .75, .975))) plot(0,0, type=&quot;n&quot;, xlim = c(0,T), ylim = range(pr), main = posterior_labels[j], xlab = &quot;time interval&quot;, ylab = &quot;state vector element&quot;) lines(x=tshot, y=pr[,1], col = &quot;gray&quot;) lines(x=tshot, y=pr[,5], col = &quot;gray&quot;) polygon(c(tshot, rev(tshot)), c(pr[,1], rev(pr[,5])), col = &quot;gray&quot;, border = NA) lines(x=tshot, y=pr[,2], col = &quot;black&quot;) lines(x=tshot, y=pr[,4], col = &quot;black&quot;) polygon(c(tshot, rev(tshot)), c(pr[,2], rev(pr[,4])), col = &quot;black&quot;, border = NA) points(x=tshot, y=pr[,3], col = &quot;red&quot;, pch = 4) } 5.0.0.3 Game-By-Game gibbs library(R2jags) simplemod &lt;- function(){ for(i in 1:n){ y[i] ~ dbinom(p, 1) } p ~ dbeta(a0,B0) } simpledat &lt;- list(y = c(rep(0,1), rep(1,3)), a0 = 1/200, B0 = 1/200 #prior is extremely skewed to edges, data is extremly 75% );simpledat$n &lt;- length(simpledat$y) simplesim &lt;- jags(simpledat, n.iter=1000, n.chains=1, n.burnin=100, parameters.to.save = &quot;p&quot;, model.file=simplemod) simplesim.mcmc &lt;- (as.mcmc(simplesim)[[1]]) model &lt;- function(){ # N observations for(i in 1:N){ result[i] ~ dbern(prob[i]) logit(prob[i]) &lt;- beta_int*int[i] + e_int[player[i]] + beta_r*logr[i] + e_r[player[i]] + beta_theta*theta[i] + e_theta[player[i]] # a random &#39;e&#39; here or is that implied? } # priors on random player effects for(j in 1:M){ e_int[j] ~ dnorm(beta_int,tau) e_r[j] ~ dnorm(beta_r,tau) e_theta[j] ~ dnorm(beta_theta,tau) } # Priors beta_int ~ dnorm(0.0,1.0E-6) beta_r ~ dnorm(0.0,1.0E-6) beta_theta ~ dnorm(0.0,1.0E-6) # Hyperpriors tau ~ dgamma(0.1,0.1) } datlist &lt;- list( logr = log(allgameshots$r), theta = allgameshots$theta, result = allgameshots$result, player = as.integer(as.factor(allgameshots$globalplayerid)), N = nrow(allgameshots), int = rep(1, nrow(allgameshots)), M = n_distinct(allgameshots$globalplayerid) ) params &lt;- c(&quot;beta_int&quot;,&quot;beta_r&quot;, &quot;beta_theta&quot;, &quot;e_int&quot;,&quot;e_r&quot;,&quot;e_theta&quot;,&quot;prob&quot;) sim &lt;- jags(data = datlist, n.iter = 1000, n.chains = 1, n.burnin = 100, #inits=list(list(p = rep(0.5, nrow(P0)))), parameters.to.save = params, model.file=model ) sim.mcmc &lt;- as.data.frame(as.mcmc(sim)[[1]]) # x_t = [1, r_t, theta_t]&#39; #HOW DO YOU GET AN R AND THETA FROM A WHOLE GAME??? # Beta = [b_0, b_r, b_theta] # P(make|attempt) = 1/(1+exp(-Beta*x_t)) #allgameshots %&gt;% group_by(gameid) %&gt;% select(r, theta) %&gt;% cbind(1,.) "],
["6-results.html", "Chapter 6 Results", " Chapter 6 Results put some plots here. and some interpretations. "],
["7-disc.html", "Chapter 7 Discussion", " Chapter 7 Discussion in conclusion, the end. "],
["references.html", "References", " References "]
]
