<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Analysis of Player Performance over Time</title>
  <meta name="description" content="Bayesian Analysis of Player Performance over Time">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Analysis of Player Performance over Time" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Analysis of Player Performance over Time" />
  
  
  

<meta name="author" content="Nathaniel Brown">


<meta name="date" content="2018-04-10">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="2-models.html">
<link rel="next" href="A-code-for-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="literature-review.html"><a href="literature-review.html"><i class="fa fa-check"></i>Literature Review</a></li>
<li class="chapter" data-level="1" data-path="1-data.html"><a href="1-data.html"><i class="fa fa-check"></i><b>1</b> Data</a><ul>
<li class="chapter" data-level="1.1" data-path="1-data.html"><a href="1-data.html#description-of-dataset"><i class="fa fa-check"></i><b>1.1</b> Description of Dataset</a></li>
<li class="chapter" data-level="1.2" data-path="1-data.html"><a href="1-data.html#data-cleaning"><i class="fa fa-check"></i><b>1.2</b> Data Cleaning</a></li>
<li class="chapter" data-level="1.3" data-path="1-data.html"><a href="1-data.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>1.3</b> Exploratory Data Analysis</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-models.html"><a href="2-models.html"><i class="fa fa-check"></i><b>2</b> Models &amp; Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="2-models.html"><a href="2-models.html#description-of-models"><i class="fa fa-check"></i><b>2.1</b> Description of Models</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-models.html"><a href="2-models.html#generalized-linear-model"><i class="fa fa-check"></i><b>2.1.1</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-models.html"><a href="2-models.html#hierarchical-generalized-linear-model"><i class="fa fa-check"></i><b>2.1.2</b> Hierarchical Generalized Linear Model</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-models.html"><a href="2-models.html#discounted-likelihood-hierarchical-model"><i class="fa fa-check"></i><b>2.1.3</b> Discounted Likelihood Hierarchical Model</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-models.html"><a href="2-models.html#analysis"><i class="fa fa-check"></i><b>2.2</b> Analysis</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-models.html"><a href="2-models.html#generalized-linear-model-1"><i class="fa fa-check"></i><b>2.2.1</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="2.2.2" data-path="2-models.html"><a href="2-models.html#hierarchical-generalized-linear-model-1"><i class="fa fa-check"></i><b>2.2.2</b> Hierarchical Generalized Linear Model</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-models.html"><a href="2-models.html#discounted-likelihood-hierarchical-model-1"><i class="fa fa-check"></i><b>2.2.3</b> Discounted Likelihood Hierarchical Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-disc.html"><a href="3-disc.html"><i class="fa fa-check"></i><b>3</b> Discussion</a><ul>
<li class="chapter" data-level="3.1" data-path="3-disc.html"><a href="3-disc.html#evaluation-of-models"><i class="fa fa-check"></i><b>3.1</b> Evaluation of Models</a></li>
<li class="chapter" data-level="3.2" data-path="3-disc.html"><a href="3-disc.html#results-from-model-with-delta-0.850"><i class="fa fa-check"></i><b>3.2</b> Results from Model with <span class="math inline">\(\delta\)</span> = 0.850</a></li>
<li class="chapter" data-level="3.3" data-path="3-disc.html"><a href="3-disc.html#conclusion"><i class="fa fa-check"></i><b>3.3</b> Conclusion</a></li>
<li class="chapter" data-level="3.4" data-path="3-disc.html"><a href="3-disc.html#future-goals"><i class="fa fa-check"></i><b>3.4</b> Future Goals</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-code-for-models.html"><a href="A-code-for-models.html"><i class="fa fa-check"></i><b>A</b> Code for Models</a><ul>
<li class="chapter" data-level="A.1" data-path="A-code-for-models.html"><a href="A-code-for-models.html#generalized-linear-model-2"><i class="fa fa-check"></i><b>A.1</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="A.2" data-path="A-code-for-models.html"><a href="A-code-for-models.html#hierarchical-generalized-linear-model-2"><i class="fa fa-check"></i><b>A.2</b> Hierarchical Generalized Linear Model</a></li>
<li class="chapter" data-level="A.3" data-path="A-code-for-models.html"><a href="A-code-for-models.html#discounted-likelihood-hierarchical-model-2"><i class="fa fa-check"></i><b>A.3</b> Discounted Likelihood Hierarchical Model</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-reproducing-evaluation-plots.html"><a href="B-reproducing-evaluation-plots.html"><i class="fa fa-check"></i><b>B</b> Reproducing Evaluation Plots</a><ul>
<li class="chapter" data-level="B.1" data-path="B-reproducing-evaluation-plots.html"><a href="B-reproducing-evaluation-plots.html#home-games-only"><i class="fa fa-check"></i><b>B.1</b> Home Games Only</a></li>
<li class="chapter" data-level="B.2" data-path="B-reproducing-evaluation-plots.html"><a href="B-reproducing-evaluation-plots.html#one-season-only"><i class="fa fa-check"></i><b>B.2</b> One Season Only</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Analysis of Player Performance over Time</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="disc" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Discussion</h1>
<!--
Our results so far suggest that some insights can be taken by predicting basketball shooting outcomes, but none of our results are more insightful than common intuition (i.e. the most frequent shooters are usually above average shooters, or the probability of making a shot decreases as distance from the basket increases). None of the models that we have built predict the out-of-sample data well. We could refine our models by including more predictors such as a proxy for fatigue (using information about total minutes played, or consecutive minutes played without a timeout), or shot difficulty (using information about the nearest defender). -->
<div id="evaluation-of-models" class="section level2">
<h2><span class="header-section-number">3.1</span> Evaluation of Models</h2>
<p>To evaluate these models, we use 5-fold cross-validation. In each train-test split, we evaluate the models’ out-of-sample classification rates (using a cutoff probability of 0.5), Brier scores (mean squared error), and log-likelihoods. The predictions and fitted values are obtained using MCMC averages; to calculate the probability for an individual shot, we calculate a response for each of the 9,500 posterior simulations, then take the average of those responses. This process used up to 20 simultaneous RStudio Pro servers provided by the Duke University Statistical Science Department. The results are plotted below in Figure <a href="3-disc.html#fig:evalplot">3.1</a>:</p>
<p><img src="thesis_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
<p></p>
<div class="figure" style="text-align: center"><span id="fig:evalplot"></span>
<img src="thesis_files/figure-html/evalplot-1.png" alt="Model Evaluation" width="672" />
<p class="caption">
Figure 3.1: Model Evaluation
</p>
</div>
<p>From Figure <a href="3-disc.html#fig:evalplot">3.1</a>, we can observe that all of the models have different strengths. The discounted likelihood model with the smallest value of <span class="math inline">\(\delta\)</span> consistently has the highest likelihood. However, it does not test as well as the other models in areas of out-of-sample classification rate and Brier score. This suggests that models with smaller values of <span class="math inline">\(\delta\)</span>, where the likelihood of an observed shot is more heavily influenced by shots closer to it, may overfit the model to the training data. The generalized linear models perform best in Brier score, but worst in log-likelihood. The hierarchical models are about the same as the GLMs, but they have a better log-likelihood performance. A model that balances the trade-off between predictive accuracy and likelihood is a discounted likelihood model with <span class="math inline">\(\delta\)</span> = 0.850.</p>
<p>In addition, we can see that the overall variation in model performance is small. For example, most of the out-of-sample classification rates fall between 0.58 and 0.62. This is within the 95% confidence interval for a random binomial proportion of 0.6 using a sample size of 40 (because there are 8 different models and 5 train-test splits for each model), which is (0.5225, 0.6775). Therefore, the evidence that the models without discounting predict better than the ones with discounting is not particularly strong.</p>
<p>For the discounted likelihood model with <span class="math inline">\(\delta\)</span> = 0.850, we build calibration plots to assess how well the estimated probabilities fit the actual proportions. To make these plots, we divide the predicted probabilities into 20 equally-sized bins, then plot these bins on the x-axis with the proportions of the actual outcomes within the bins on the y-axis. The horizontal bars represent the bin width, and the vertical bars represent a 95% confidence interval of the proportions. The red line of slope 1 represents equality between the bin medians and the empirical probabilities within the bins. In Figure <a href="3-disc.html#fig:caliplot">3.2</a>, we present these plots for a full training set and a testing set.</p>
<div class="figure" style="text-align: center"><span id="fig:caliplot"></span>
<img src="thesis_files/figure-html/caliplot-1.png" alt="Calibration Plots for Discounted Likelihood Model, $\delta$ = 0.850" width="672" />
<p class="caption">
Figure 3.2: Calibration Plots for Discounted Likelihood Model, <span class="math inline">\(\delta\)</span> = 0.850
</p>
</div>
<p></p>
<p>We can see that the confidence intervals on the training set all cross the line of slope 1, which shows that the model output reliably fits the probabilities. In the testing set, however, the predictions only cross this line between about 0.3 and 0.75. In addition, the widths of the bins on the edges show that the model is not likely to predict values close to 0 or 1.</p>
</div>
<div id="results-from-model-with-delta-0.850" class="section level2">
<h2><span class="header-section-number">3.2</span> Results from Model with <span class="math inline">\(\delta\)</span> = 0.850</h2>
<p>To illustrate results from the discounted likelihood model with <span class="math inline">\(\delta\)</span> = 0.850, we replicate the plots in Figures <a href="2-models.html#fig:discplot750">2.5</a> and <a href="2-models.html#fig:discplot999">2.6</a>. The results are shown in Figure <a href="3-disc.html#fig:discplot850">3.3</a>.</p>
<div class="figure" style="text-align: right"><span id="fig:discplot850"></span>
<img src="thesis_files/figure-html/discplot850-1.png" alt="Parameters for Two Players and Population over Time, $\delta$ = 0.850" width="90%" />
<p class="caption">
Figure 3.3: Parameters for Two Players and Population over Time, <span class="math inline">\(\delta\)</span> = 0.850
</p>
</div>
<p>Figure <a href="3-disc.html#fig:discplot850">3.3</a> has smoother changes over time than in Figure <a href="2-models.html#fig:discplot750">2.5</a>, where <span class="math inline">\(\delta\)</span> = 0.750, which could indicate that there is less overfitting. One surprising result from this model is how the distance parameters slightly increase over time, and the intercepts slightly decrease. This could be a result of team shot selection evolving throughout the season, or just a coincidental signal.</p>
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">3.3</span> Conclusion</h2>
<p>The evaluations of the models show that there is some weak evidence for time-dependency in shooting success rate in this dataset of player-tracking data from the Duke Men’s Basketball team. Allowing predictors of shot success to shift based on recent success does not significantly improve the predictive accuracy of a model. However, we do see a systematic improvement in likelihood for smaller discount factors (i.e., more emphasis on recent shots, and therefore support of “streakiness”). Weaknesses of the discounting model include a smaller sample size and poorer out-of-sample prediction. Takeaways that we observed in other models include the fact that the angle of the shot only matters for certain players, and it is not a significant predictor of shot success between all players. Also, the effects of home-court advantage are not strong in this dataset, possibly due to the fact that most of the games away from home are missing.</p>
<p>To account for possible unexplained variation between seasons, and for variation introduced from having such a small population of road games, I repeated this analysis on a subset of the data that only consisted of shots from available games in one season (25 games), and shots from all home games (82 games). The results were similar, except for increased uncertainty due to smaller sample sizes. The model evaluation plots show similar patterns to the ones in Figure <a href="3-disc.html#fig:evalplot">3.1</a>, and they are presented in Appendix B.</p>
</div>
<div id="future-goals" class="section level2">
<h2><span class="header-section-number">3.4</span> Future Goals</h2>
<p>Future goals for this research are to build a better-fitting model to predict basketball shots using more advanced factors that can be approximated from the dataset. Possibilities for this include reparametrizing the location of a shot using categories (e.g., corner three-point shots, heaves from half-court) using the distance of the nearest defender as a proxy for defense quality, or using the amount of time a player has played without a substitution or timeout to approximate fatigue. In addition, we make the unrealistic assumption that every player exhibits the same amount of shooting streakiness with our discounted likelihood models. We could improve upon this assumption in the discounted likelihood models by adding a random effect on <span class="math inline">\(\delta\)</span>, to allow it to vary by player.</p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="2-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="A-code-for-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
